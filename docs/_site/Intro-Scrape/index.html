<!DOCTYPE html>

<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="author" content="Lynn Root">
<meta name="description" content="Five Life Jackets to Throw at the New Coder - Python tutorials">
<meta name="generator" content="mynt v0.2.2">

<link rel="shortcut icon" href="/assets/images/favicon.ico" type="image/x-icon">



<link rel="stylesheet" href="/assets/css/screen.css" type="text/css">
<link rel="stylesheet" href="/assets/css/style.css" type="text/css">
<link rel="stylesheet" href="/assets/css/glyphicons.css" type="text/css">
<link rel="stylesheet" href="/assets/css/pygments.css" type="text/css">
<script src="/assets/js/modernizr.js"></script>


    
    <title>Introduction to the Web Scraping Tutorial using Scrapy and PostGres &ndash; New Coder</title>
</head>

<body>
    <div class="ribbon">
      <a href="https://github.com/econchick/new-coder">Contribute on GitHub</a>
    </div>
    <div id="container">
        <div id="nav">
            <ul>
                <li><a href="/">Home</a></li>
                <li><a href="/about/">About</a></li>
                <li><a href="/tutorials/">Tutorials</a></li>
                <li><a href="/contact/">Need help? Want to say hi?</a></li>
            </ul>
            
        </div>
        
        <div id="header">
            <h1><a href="/">New Coder<i class="glyphicons-icon life_preserver"></i></a></h1>
            <h2>Five Life Jackets to Throw at the New Coder</h2>
        </div>

        <div id="content">
            
    <div class="item">
        <div class="header">
            <h1>Introduction to the Web Scraping Tutorial using Scrapy and PostGres</h1>
        </div>
        
        <div class="body">
            <p>This tutorial will walk you through how to make a web scraper, save the data to a database, and schedule the scraper to run daily. We will also introduce you to some simple queries to use on the database so you can query the information you scraped at your leisure.</p>
<h3>The Project</h3>
<p>We will build a web scraper using <a href="http://scrapy.org/">Scrapy</a> to scroll through <a href="http://www.livingsocial.com">LivingSocial</a>, and save local deals to our Postgres database. We&#39;ll schedule our computer to run this script daily, so that rather than getting those annoying emails, we can query our database when we want a deal on sky diving or hot yoga.</p>
<h3>About Web Scrapers</h3>
<p>Web scraping is a technique for gathering data or information on web pages. You could revisit your favorite web site every time it updates for new information. Or you could write a web scraper to have it do it for you!  </p>

<p>A <strong>scraper</strong> is just a script that parses an HTML site - much like the parser we wrote for our CSV data in our <a href="/dataviz/">DataViz</a> tutorial.</p>
<h3>About Scrapy</h3>
<p><a href="http://scrapy.org/">Scrapy</a> is one of the popular web scraping frameworks written in Python. It uses <a href="http://twistedmatrix.com/trac/">Twisted</a>, a Python networking engine, and <a href="http://lxml.de/">lxml</a>, a Python XML + HTML parser.  </p>

<p><strong>Note for the curious:</strong> The lxml library builds on C libraries for parsing, giving the lxml library speed. This is why we needed to install a compiler.</p>

<p>Scrapy also has this great <a href="http://doc.scrapy.org/en/0.16/intro/tutorial.html">tutorial</a> which this follows closely, but extends beyond it with the use of Postgres and a cronjob.</p>
<h3>About Postgres</h3>
<p>Postgres is a very popular database that is free and open source. Other popular databases include MySql, MS SQL, and MongoDB.  Which database you choose depends on what you&#39;ll need it for.</p>

<p>To learn why Postgres is go great, <a href="http://twitter.com/craigkerstiens">Craig Kerstiens</a> of Heroku wrote up a nice <a href="http://www.craigkerstiens.com/2012/04/30/why-postgres/">explanation</a>.</p>

<p>As an aside: when I first started learning how to code, the concept of having a datbase <em>on</em> my computer blew me away. I assumed databases lived in headless computers that could handle the ubiquitous data. Turns out, it&#39;s just like a simple program on your comptuer. Sure, if you&#39;re a company, you&#39;d want machines dedicated for serving up production-level data. But we&#39;re not heavy-duty number crunching (yet!).</p>
<h3>What is a cronjob?</h3>
<p>A cron is a job scheduler for Unix-like computers. It basis its schedule off of a crontab (cron table), of which each line on the table is a job (cron job).</p>

<p>You can schedule a cron job to go every minute, every hour, every day, etc. Wiki has an <a href="http://en.wikipedia.org/wiki/Cron#Predefined_scheduling_definitions">overview</a> of the actual syntax to use for a cron job.</p>

<p><strong>If you&#39;re on a Windows Machine</strong>, the cron-equivalent is the <a href="http://support.microsoft.com/kb/308569">Windows Task Scheduler</a>.  The scope of the tutorial does not cover how to configure the Windows Task Scheduler, but you can r<a href="http://technet.microsoft.com/en-us/library/bb726974.aspx">read how</a> or use the <a href="http://technet.microsoft.com/en-us/library/cc725744.aspx">schtask</a> tool.</p>

<p><a href="/Part-1-Scraper-Setup/">Move onto the Setup &rarr;</a></p>

        </div>
    </div>

        </div>
        
        <div id="footer">
            <p>Copyright &copy; 2013 Lynn Root &ndash; powered by <a href="http://mynt.mirroredwhite.com/">mynt</a></p>
        </div>
    </div>
</body>
</html>