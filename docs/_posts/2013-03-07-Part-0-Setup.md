---
layout: post.html
title: "Part 0: Setup"
tags: [scrape]
---

Walkthrough of scraping a webpage and saving it to a database.

### Initial Requirements:
* [Python 2.x](http://www.python.org/download/releases/2.7.3/)
* A C compiler: [GCC](http://gcc.gnu.org/) or [clang](http://clang.llvm.org/) – the Scrapy library has some C extensions, which will need to be compiled.
	* Mac: 
		* You will need [XCode](http://developer.apple.com/xcode). Once you have XCode on your machine, you will need to navigate to **Preferences** –> **Downloads** –> and select **Command Line Tools** to download & install.
		* You may need to install libxml2 and libxslt (but most-likely is already nstalled). You can install the libraries from macports: `sudo port install libxml2 libxslt`
	* Fedora: `sudo yum install gcc python-devel libxml libxslt libxml-devel libxslt-devel openssl openssl-devel`
	* Ubuntu: `sudo apt-get install build-essential python-dev libxml2-dev libxslt-dev` – you may need to run `sudo apt-get update` first.
* [PostgreSQL](http://www.postgresql.org/download/)
	* If you have a Mac, I highly suggest installing Postgres through [Postgres.app](http://postgresapp.com/) for simple setup.
* [virtualenv](http://pypi.python.org/pypi/virtualenv) You can either download directly, or:
	* Mac: ` $ sudo easy_install virtualenv`
	* Ubuntu: `$ sudo apt-get virtualenv`
	* Fedora: `$ sudo yum install python-virtualenv`
	* Windows: [Download manually](http://pypi.python.org/pypi/virtualenv)
* [virtualenvwrapper](http://pypi.python.org/pypi/virtualenvwrapper) You can either download it directly, or:
	* Mac: `$ sudo easy_install virtualenvwrapper`
	* Ubuntu: `$ sudo apt-get virtualenvwrapper`
	* Fedora: `$ sudo yum install python-virtualenvwrapper`
	* For Mac, Ubuntu, and Fedora:
		* `$ export WORKON_HOME=~/Envs`
		* `$ mkdir -p $WORKON_HOME`
		* `$ source /usr/local/bin/virtualenvwrapper.sh`
	* Windows: [Download manually](http://pypi.python.org/pypi/virtualenvwrapper) and follow install instructions

### Setup
Within your terminal:

* Change into the Web Scraping project.

```bash
$ cd new-coder/scrape
```
* Make sure you’ve installed [virtualenvwrapper](http://pypi.python.org/pypi/virtualenvwrapper) and followed the steps above from Initial Requirements above to set up your terminal correctly.  More information can be find at virtualenvwrapper’s [docs](http://virtualenvwrapper.readthedocs.org/en/latest/). 
* Make a virtual environment specific to your Scrape project:

```bash
$ mkvirtualenv ScrapeProj
``` 
* You should see `(ScrapeProj)` before your prompt. Now install package requirements with the following command for this project. 

```bash
(ScrapeProj) $ pip install -r requirements.txt
``` 
* Your virtual environment will store the required packages in a self-contained area to not mess up with other Python projects.

[Continue on to Part 1: Scraper Setup &rarr;]( {{ get_url("Part-1-Scraper-Setup/")}})