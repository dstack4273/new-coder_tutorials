---
layout: post.html
title: "Part 1: Scraper Setup"
tags: [scrape]
---


Building the scraper setup portion of the tutorial.

## Directory setup

Create the following file/directory hierarchy within your `scrape_workspace` folder, mimicking that of the `scrape` directory of the repo:

```bash
└── my_scraper/
    └── scraper_app/
       └── spiders/
```

You can do so with the following commands:

```bash
(ScrapeProj) $ mkdir -p my_scraper/scraper_app/spiders
```


## Define our Items

Create an `items.py` file in the `my_scraper/scraper_app/` directory.  In our `items.py` file, scrapy needs us to define containers for the data that we plan to scrape. If you have worked through the Django [tutorial](https://docs.djangoproject.com/en/1.5/intro/tutorial01/) at one point, you'll see that the `items.py` is similar to `models.py` in Django.

First, using scrapy’s item module, we import `Item` and `Field`:

```python
from scrapy.item import Item, Field
```

Simple enough. Now we’ll create a class, and name it after the kind of data that we’ll scrape, `LivingSocialDeal`:

```python
class LivingSocialDeal(Item):
    """Livingsocial container (dictionary-like object) for scraped data"""
```

For our `LivingSocialDeal` class, we inherit from `Item` - which basically takes come pre-defined objects that scrapy has already built for us.

<div class="panel panel-default">
  <div class="panel-heading">For the Curious</div>
  <div class="panel-body">
You can think of class inheritance like the birds and the bees. For instance, we can have a base class, <code>class Human(object)</code>, that will have some human attributes - like a function for running, for bathing, eating, etc.  Then we can inherit from the <code>Human</code> class to make a new class, <code>class Superwoman(Human)</code>. Because we inherit from <code>Human</code>, we can still access the running, eating, bathing functions. But - perhaps Superwoman runs <i>faster</i> than the average human, so we can <i>redefine</i> the running function. This basically rewrites over Human’s running function.
</div>
</div>

Or maybe we want to add to <code>Human</code>’s <code>eating()</code> method by adding an intact of 1000 more calories (being a Superwoman requires a lot of energy!). We can define an <code>eating()</code> function within our <code>Superwoman</code> class, then call <code>super()</code> on the method,

Perhaps Superwomen should also fly. We can define a separate <code>Flying(object)</code> class. Now, when we define our <code>Superwoman()</code> class, we can inherit <b>both</b> from <code>Human</code> and <code>Flying</code> – called multiple inheritance: <code>class Superwoman(Human, Flying)</code>.
</div>


Let’s add some items that we actually want to collect. We assign them to `Field()` because that is how we specify metadata to scrapy:

```python
class LivingSocialDeal(Item):
    """Livingsocial container (dictionary-like object) for scraped data"""
    title = Field()
    link = Field()
    location = Field()
    original_price = Field()
    price = Field()
    end_date = Field()
```

Nothing too hard - that was it. In scrapy, there are no other field types, unlike Django. So, we’re sort of stuck with `Field()`.

Let’s play around with this in the Python terminal. Make sure your `ScrapeProj` virtualenv is activated.

```bash
>>> from scrapy.item import Item, Field
>>> from items import LivingSocialDeal
>>> deal = LivingSocialDeal(title="$20 off yoga classes", price="50")
>>> print deal
LivingSocialDeal(title='$20 off yoga classes', price='50')
>>> deal['title']
'$20 off yoga classes'
>>> deal.get('title')
'$20 off yoga classes'
>>> deal['price']
'50'
>>> deal['location'] = "New York"
>>> deal['location']
'New York'
```

The scrapy `Item` class behaves very similar to Python’s dictionaries with the ability to get keys and values.

Now that it’s all setup, let’s write spider!

<br/>
<nav>
  <ul class="pager">
    <li class="previous"><a href="{{ get_url('/scrape/part-0/') }}"><span aria-hidden="true">&larr;</span> Part 0: Setup</a></li>
    <li class="next"><a href="{{ get_url('/scrape/part-2/') }}">Part 2: Writing our Spider <span aria-hidden="true">&rarr;</span></a></li>
  </ul>
</nav>
